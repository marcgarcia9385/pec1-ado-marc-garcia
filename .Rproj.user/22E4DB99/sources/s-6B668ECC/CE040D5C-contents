---
title: "Debate 2: Analisis de datos Ómicos"
author: "Marc Garcia"
date: "20/3/2020"
output:
  html_document:
    theme: united
    toc: yes
    toc_float: yes
  pdf_document:
    toc: yes
header-includes:
  - \usepackage{booktabs}
---


* * *

<div align = "justify">

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(root.dir = "C:/Users/USER/Documents/Màster Bioestadística i Bioinfo/Análisis de datos Ómicos/breast cancer/")

```

**1) Supón que deseas tener en tu ordenador una copia de los repositorios:**

<br>

+ https://github.com/ASPteaching/Analisis_de_datos_omicos-Materiales_para_un_curso
+ https://github.com/ASPteaching/Omics_Data_Analysis-Case_Study_1-Microarrays

<br>

**Puedes hacerlo de dos formas. Clonando los repositorios o descargándolos. Intenta hacerlo de la primera forma y si tienes dificultades coméntalo en el foro.**

<br>

**Descarga manual & GitHub Desktop:**

<br>

En un primer lugar, ya que no tenía la aplicación de *GitHub Desktop* instalada ni tampoco una cuenta opté por, desde mi navegador, descargar los archivos zip y descomprimirlos en mi directorio de trabajo. Sin embargo, después de investigar un poco acerca de como funciona esta aplicación, repetí el proceso y entendí que esta segunda alternativa era mucho más rápida y práctica. Una vez abierto GitHub Desktop, es tan fácil como clicar sobre el botón add, pegar la url del repositorio git y darle a Clone. Una herramienta muy útil sin duda.

<br>

**Clonando repos desde R-Studio:**

<br>

Teniendo en cuenta que en el enunciado se pedía que clonaramos el repo desde R-Studio y yo lo he hecho con GitHub Desktop, complemento mi respuesta. Clonar un repo desde R-Studio es muy fácil. Me he ayudado del contenido de un enlace que ha adjuntado un compañero donde, en mi opinión, esta muy bien explicado (https://cfss.uchicago.edu/setup/git-with-rstudio/).

<br>

En primer lugar debemos comprobar que R-Studio encuentra a Git. Para que así sea se deben cumplir unas premisas:

<br>

- Al dirigimos a File/New Project debería aparecernos la opción Version Control
- Si seleccionamos New Project/New Directory/New Project nos debería aparecer la casilla Create a git repository
- Si creamos un nuevo proyecto marcando la casilla Create a git repository, nos debería aparecer una nueva pestaña al lado de la pestaña de Environment (Git)

<br>

Por otro lado, para clonar un repo de Github desde R-Studio, lo que debemos hacer es:

<br>

- Nos dirigimos a File/New Project
- Seleccionamos Version Control
- Seleccionamos Git
- Pegamos la url del repo a clonar, especificamos un nombre para el directorio y seleccionamos la url donde queremos crearlo.
- Le damos a Create Project
- Aparecerá una pantalla de carga donde se mostrará el avance del clonaje

<br>

**2) Una de las etapas iniciales en el preprocesado de los datos de microarrays es la normalización, en donde se transforman los datos para eliminar “sesgos sistemáticos” y para hacer los datos comparables.**

<br>

**A) ¿Qué problemas y ventajas os parece que conlleva la normalización?**

<br>

La normalización de los datos de experimentos de microarrays y, en definitiva de cualquier tipo de datos, se utiliza para permitir la comparación entre muestras o variables. Si nos centramos en el caso de los microarrays, este proceso permite comparar los datos de los diferentes chips de las diferentes unidades experimentales. De este modo, gracias a la normalización, se corrigen las diferencias sistemáticas entre muestras, pudiendo asignar las variaciones entre grupos a una verdadera variación biológica y no a sesgos técnicos. 

<br>

En cuanto a los problemas que pueden derivarse de esta práctica, en mi opinión son principalmente dos. El primero es consecuencia del la gran variedad de métodos de normalización que existen. Puede llegar a ser confuso escojer cuál utilizar pero lo que tenemos que entender es que no podemos comparar datos normalizados mediante diferentes protocolos. El segundo problema es bastante lógico. La normalización implica homogeneidad. Cuando normalizamos, homogeneizamos. En consecuencia puede ser que eliminemos cierta variabilidad que se ha considerado como ruido pero que esta variabilidad sea importante para interpretar los resultados de nuestro experimento.

<br>

**B) Hay multitud de métodos de normalización (¿Cuántos distintos podéis encontrar?). ¿A que puede deberse que haya tantos? ¿Cómo podemos compararlos para decidir cuál es el más adecuado?**

<br>

Tal y como se ha comentado en el apartado anterior, existen muchos métodos de normalización. Prueba de ello es la gran cantidad de artículos científicos relacionados con este tema disponibles en portales de divulgación científica. Probablemente esto se debe a que la normalización es un paso crítico en los experimentos basados en microarrays: si no conseguimos normalizar correctamente los datos, no se pueden comparar. Además, a mejor normalización, mejores resultados y conclusiones más precisas. Independientemente de la variedad de protocolos, los métodos de normalización se pueden englobar en dos grandes grupos. El primer grupo, denominado **normalización global**, se basa en modificar todas las entradas de la matriz de expresión en una cierta cantidad **c**. El segundo grupo, denominado **normalización dependiente de la intensidad**, consiste en hacer modificaciones específicas que variarán en función de la entrada de la matriz de expresión.

<br>

En cualquier caso y sin entrar en detalle, el método más adecuado acostumbra a depender de varios factores. Como ya han comentado mis compañeros. los más importantes son el tipo de datos, el tamaño del dataset, la sensibilidad o el grado de diferencia entre las muestras a comparar.


<br>

**3) Una vez realizada la selección de genes solemos hacer un ajuste de p-valores para compensar por el hecho de que hemos hecho no uno sino muchos contrastes (uno por gen). En ocasiones el número de genes que se seleccionan tras realizar el ajuste de p-valores es muy bajo por lo que una práctica bastante habitual es aflojar el criterio y seleccionar genes en base a p-valores sin ajustar. ¿Crees que esta aproximación es adecuada o incorrecta? ¿Qué argumentos se pueden esgrimir a favor de hacerlo? ¿Y a favor de no hacerlo?**

<br>

Tal y como se comenta en el enunciado, el problema de la multiplicidad de los tests es un punto crítico y que genera controversia. La teoria es clara. La probabilidad de cometer un error de tipo I en único test es $\alpha$. Ahora bien, si este es mayor que 1, el error de tipo I (del total de los tests) se ve afectado por su número, siendo:

<br>

$error \ tipo \ I = 1 - (1 - \alpha)^n$

<br>

Dónde el número de tests es n. De esta manera, para un número considerable y adecuado para un experimento de microarrays (del orden de miles), la probabilidad de cometer un error de tipo I será casi 1. Precisamente para evitar estas situaciones se ajustan los p-valores mediante métodos como la corrección de Bonferroni, el método de Benjamini & Hochberg o el método de Benjamini & Yekutieli. El problema es que estas correciones aumentan el p-valor de los tests originales y es posible que identifiquemos muy pocos genes expresados de forma diferencial. 

<br>

Posicionarse a favor o en contra es complicado. En mi opinión depende de muchos factores. Aún siendo cierto que la teoría es la que es y no deberíamos saltarnos ninguno de estos principios para obtener más resultados o resultados más atractivos, creo que depende mucho del contexto. Puede ser por ejemplo que estemos estudiando un grupo de genes sobre los cuáles ya se tiene información y se puedan aplicar ciertas excepciones. Es decir, en mi opinión creo que se debería ajustar los p-valores siempre y, después, si observamos que son demasiado altos, adaptar el nivel de significación ($\alpha$) en función de estos. De esta manera estamos respetando los principios de la multiplicidad de los tests y lo único que estamos haciendo es variar el nivel de significación. 

<br>

Otra opción que han comentado mis compañeros y que resulta interesante consiste en hacer una primera selección con los p-valores ajustados y luego aflojar el criterio y seleccionar algunos genes más considerando su p-valor no ajustado. Ahora bien, si nos decantamos por esta opción, el análisis con microarrays se convierte en un primer estudio preliminar que debe ser validado por técnicas como la qRT-PCR, donde se analizan los genes uno por uno. Se puede minimizar el efecto de la multiplicidad de los tests aplicando un filtrado previo sobre todos los genes del array. De esta manera, basándonos normalmente en la varianza, eliminamos aquellos genes con menos probabilidad de estar diferencialmente expresados. Así pues, al realizar menos tests después del filtrado, el problema de la multiplicidad se reduce un poco.

<br>

**4) La selección de genes diferencialmente expresados puede hacerse de formas distintas. En situaciones experimentales complejas una buena estrategia es utilizar los modelos lineales implementados en el paquete lima (“linear models for microarrays”). El ejercicio adjunto plantea algunas situaciones experimentales y te pide que las representes mediante un modelo lineal. Escoge una de ellas y resuélvela. Si ya han sido todas resueltas puedes usar algún ejemplo de los que se han comentado en clase.**

<br>

<u>Comparison between three types of breast cancer</u>

<br>

This case study is based on a paper published in http://www.ncbi.nlm.nih.gov/pubmed/15897907 whose data are available in GEO as series GSE1561 series on the following link http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE1561.

<br>

The researchers investigated three types of breast cancer tumors: **apocrine (APO)**, **basal (BAS)** and **luminal (LUMI)**. The classification is based on the resistance of tumors to estrogen and androgen receptors.

<br>

+ Tumors classified as “APO” are negative for estrogen receptor (ER-) and positive for the androgen receptor (AR +).
+ Those classified as “LUMI” are ER + and AR + and
+ Those classified as “BAS” are ER- and AR.

<br>

The assignment of each sample to an experimental group can be obtained from this link: http://www.ncbi.nlm.nih.gov/geo/gds/profileGraph.cgi?gds=1329

<br>

Obviously this is an observational study but its analysis can be done using a linear model approach as well.

<br>

**1) Identify the experimental factors and their levels.**

<br>

Se trata de un estudio definido por un factor con tres niveles. Este factor segrega las muestras (tumores) en tres unidades experimentales, una por cada nivel:

<br>

+ **Tumores APO:** 5 tumores sin el receptor de estrogeno (ER-) y con el receptor de androgeno (AR+).
+ **Tumores LUMI:** tumores con ambos receptores (ER+, AR+).
+ **Tumores BAS:** tumores sin ninguno de los receptores (ER-, AR-).

<br>

**2) Write down the design matrix associated with this study design.**

<br>

Antes de generar la matriz de diseño, debemos seguir una serie de pasos de forma secuencial. Lo primero es preparar un subconjunto de directorios donde almacenar los ficheros de datos (ficheros CEL + targets) y los ficheros de resultados.

<br>

```{r creando directorios, comment=NA, eval=F}

# Creando la estructura de directorios

dir.create("breast cancer")
dir.create("breast cancer/data")
dir.create("breast cancer/results")

```

<br>

A continuación, guardaremos los ficheros `.CEL` del experimento en la carpeta `data`. Los podemos descargar desde el siguiente [enlace](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE1561) (archivo `GSE1561_RAW.tar`). A continuación, procedermos a generar de forma manual el archivo `targets`. Este archivo puede ser generado, utilizando `Microsoft Excel` o un software parecido, a partir de la información contenida en este [enlace](https://www.ncbi.nlm.nih.gov/geo/tools/profileGraph.cgi?ID=GDS1329). 

<br>

Ahora ya podemos cargar los archivos `.CEL` y `targets` y crear un objeto de tipo `ExpressionSet`.

<br>

```{r creando ES, comment=NA, message=F, warning=F}

# Cargando paquetes

library(Biobase)
library(oligo)

# Leyendo archivos CEL + targets

data_dir <- file.path("data/")
cel_files <- list.celfiles(data_dir, 
                           full.names = T)

targets <- read.AnnotatedDataFrame(path = data_dir,
                                   filename = "targets.csv", sep = ";", 
                                   header = T, 
                                   row.names = 1)

# Cambiando el nombre de las muestras

raw_data <- read.celfiles(filenames = cel_files, 
                           phenoData = targets)

rownames(raw_data@phenoData) <- targets@data$ShortName
sampleNames(raw_data) <- targets@data$ShortName

```

<br>

Aunque los siguientes pasos no son estrictamente necesarios para generar la matriz de diseño, ya que se realizan antes de su construciión hemops decidido incuirlos. Primeramente, realizaremos un control de calidad para determinar que no existe ningún array defectuoso y podemos realizar la normalización sin preocuparnos. Para ello, utilizaremos la función `arrayQualityMetrics()` del paquete con el mismo nombre. 

<br>

```{r control de calidad (raw data), comment=NA, eval=F}

# Primer control de calidad (raw data)

library(arrayQualityMetrics)

arrayQualityMetrics(expressionset = raw_data, 
                    outdir = file.path("results/", "QCDir.raw"), 
                    force = T, 
                    intgroup = "Group")
```

<br>

Observamos que ninguno de los arrays contiene más de dos asteriscos y por lo tanto asumimos que no existe ninguna muestra defectuosa y que los datos de todos los arrays pueden ser normalizados. Para normalizar los datos utilizaremos la función `rma()` del paquete `oligo`. 

<br>

**NOTA:** podemos complementar el output de esta función generando nosotros de forma manual ciertos plots como el PCA plot o el boxplot.

<br>

```{r data normalization, comment=NA}

# Normalizando los datos

norm_data <- rma(raw_data)

```

<br>

Después de la normalización es interesante realizar de nuevo un control de calidad.

<br>

```{r control de calidad (norm_data), comment=NA, eval=F}

# Segundo control de calidad (norm data)

arrayQualityMetrics(expressionset = norm_data, 
                    outdir = file.path("results/", "QCDir.norm"), 
                    force = T, 
                    intgroup = "Group")

```

<br>

Observando el informe final podemos concluir que la normalización ha funcionado. Sólo se observan dos arrays con un asterisco, buena señal. Por otro lado, el patrón del boxplot es el esperado. Sin embargo, en cuanto al PCA plot, no vemos una segregación clara de los grupos. Aunque no tiene porque ser una mala señal, es importante especificarlo.

<br>

A continuación, filtraremos aquellos genes con una variabilidad menor, los eliminaremos. Esto se hace parar reducir el número de tests i minimizar el problema de la multiplicidad. Primero crearemos un plot que mostrará la variabilidad total de todos los genes ordenada de menor a mayor. De este modo podremos definir un punto de inflexión a partir del cual filtrar. En segundo lugar, mediante la función `nsFilter()` del paquete `genefilter` eliminaremos aquellos genes con una variabilidad menor que el punto de inflexión y también aquellos repetidos o para los cuales no dispongamos de anotaciones.

<br>

```{r detecting least variable genes, comment=NA}

# Matriz de expresión de datos normalizados

exprs_norm_data <- exprs(norm_data)

# SD plot

sds <- apply(X = exprs_norm_data, MARGIN = 1, FUN = sd)
sds_0 <- sort(sds)

plot(x = 1:length(sds_0), 
     y = sds_0, 
     main = "Distribution of variability for all genes", 
     xlab = "Gene index (from least to most variable)", 
     ylab = "Standard deviation", 
     abline(v = length(sds) * c(0.9, 0.95), 
            lty = 2))

# Cargando paquetes: genefilter & mogene21sttranscriptcluster.db

library(genefilter)
library(hgu133plus2.db)

# Filtrando genes

annotation(norm_data) <- "hgu133plus2.db"

filtered <- nsFilter(eset = norm_data, 
                     require.entrez = T, 
                     remove.dupEntrez = T, 
                     var.filter = T, 
                     var.func = IQR, 
                     var.cutoff = 0.75, 
                     filterByQuantile = T, 
                     feature.exclude = "^AFFX")

print(filtered$filter.log)

norm_filtered_data <- filtered$eset
exprs_norm_filtered_data <- exprs(norm_filtered_data)

```

<br>

Ahora que ya tenemos los datos normalizados y filtrados, ya podemos construir la **matriz de diseño**. Para hacerlo utilizaremos la función `model.marix()` del paquete `stats`. Básicamente, esta matriz describe la localización de cada muestra en un grupo o condición experimental. La matriz contiene tantas filas como muestras y tantas columnas como grupos. La localización de las muestras se indica con 1s y su ausencia con 0s.

<br>

```{r defining the design matrix, comment=NA}

# Generating the design matrix

design_matrix <- model.matrix(object = ~ 0 + Group, 
                              data = pData(object = norm_filtered_data))

colnames(design_matrix) <- c("APO", "BAS", "LUMI")

print(design_matrix)

```

<br>

**3) Build the contrast matrix needed to compare each tumor type with the oher two, that is:**

<br>

+ “APO” vs “LUMI”
+ “APO” vs “BAS”
+ “LUMI” vas “BAS”

<br>

Una vez construida la matriz de diseño, para construir la matriz de contrastes, utilizaremos la función `makeContrasts()` del paquete `limma`. Esta matriz mostrará en las filas los diferentes grupos del estudio y en las columnas los diferentes contrastes. Se marcará con 1s t -1s los grupos involucrados en cada uno de los contrastes.

<br>

```{r defining the contrast matrix, comment=NA}

contrast_matrix <- makeContrasts(APOvsLUMI = APO-LUMI, 
                                 APOvsBAS = APO-BAS, 
                                 LUMIvsBAS = LUMI-BAS, 
                                 levels = design_matrix)

print(contrast_matrix)

```

</div>